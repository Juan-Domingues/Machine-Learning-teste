"""
DIAGNÃ“STICO DE OVERFITTING - REVISÃƒO TÃ‰CNICA
ðŸ” VerificaÃ§Ã£o rigorosa do pipeline de 75%
"""

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import TimeSeriesSplit, train_test_split
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

def diagnostico_completo():
    """
    DiagnÃ³stico completo para detectar overfitting
    """
    print("="*80)
    print("ðŸ” DIAGNÃ“STICO DE OVERFITTING - PIPELINE 75%")
    print("="*80)
    
    # 1. CARREGAMENTO DOS DADOS
    print("\nðŸ“Š ETAPA 1: AnÃ¡lise dos Dados")
    end_date = datetime.now()
    start_date = end_date - timedelta(days=int(1.5 * 365))
    data = yf.download('^BVSP', start=start_date, end=end_date)
    
    if isinstance(data.columns, pd.MultiIndex):
        data.columns = data.columns.get_level_values(0)
    
    print(f"ðŸ“… PerÃ­odo: {start_date.date()} a {end_date.date()}")
    print(f"ðŸ“Š Total de dias: {len(data)}")
    print(f"ðŸ“ˆ Dados faltantes: {data.isnull().sum().sum()}")
    
    # EstatÃ­sticas descritivas
    print(f"\nðŸ“Š ESTATÃSTICAS DESCRITIVAS:")
    print(f"   Close - Min: {data['Close'].min():.2f}, Max: {data['Close'].max():.2f}")
    print(f"   Volume - Min: {data['Volume'].min():,.0f}, Max: {data['Volume'].max():,.0f}")
    
    # 2. CRIAÃ‡ÃƒO DAS FEATURES (EXATAMENTE COMO NO MAIN)
    print(f"\nðŸ”§ ETAPA 2: CriaÃ§Ã£o das Features")
    
    data['Return'] = data['Close'].pct_change()
    data['Target'] = (data['Close'].shift(-1) > data['Close']).astype(int)
    
    # TRIO BASE
    data['SMA_5'] = data['Close'].rolling(5).mean()
    data['Price_above_SMA5'] = (data['Close'] > data['SMA_5']).astype(int)
    
    data['Volume_MA_20'] = data['Volume'].rolling(20).mean()
    data['Volume_above_avg'] = (data['Volume'] > data['Volume_MA_20']).astype(int)
    
    data['Return_lag1'] = data['Return'].shift(1)
    data['Positive_return_lag1'] = (data['Return_lag1'] > 0).astype(int)
    
    # FEATURES DIFERENCIAIS
    data['SMA_10'] = data['Close'].rolling(10).mean()
    data['Trend_strong'] = (data['SMA_5'] > data['SMA_10']).astype(int)
    
    data['Return_lag2'] = data['Return'].shift(2)
    data['Momentum_strong'] = ((data['Return_lag1'] > 0) & (data['Return_lag2'] > 0)).astype(int)
    
    features = [
        'Price_above_SMA5', 'Volume_above_avg', 'Positive_return_lag1',
        'Trend_strong', 'Momentum_strong'
    ]
    
    dataset = data[features + ['Target']].dropna()
    
    print(f"âœ… Features criadas: {len(features)}")
    print(f"ðŸ“Š Dataset final: {len(dataset)} observaÃ§Ãµes")
    
    # 3. ANÃLISE EXPLORATÃ“RIA DAS FEATURES
    print(f"\nðŸ“ˆ ETAPA 3: AnÃ¡lise ExploratÃ³ria das Features")
    
    X = dataset[features]
    y = dataset['Target']
    
    print(f"ðŸ“Š DistribuiÃ§Ã£o do Target:")
    target_dist = y.value_counts(normalize=True)
    print(f"   Classe 0 (Baixa): {target_dist[0]:.1%}")
    print(f"   Classe 1 (Alta): {target_dist[1]:.1%}")
    
    print(f"\nðŸ“Š CorrelaÃ§Ã£o Features vs Target:")
    for feature in features:
        corr = dataset[feature].corr(dataset['Target'])
        print(f"   {feature}: {corr:.3f}")
    
    print(f"\nðŸ“Š EstatÃ­sticas das Features:")
    for feature in features:
        mean_val = dataset[feature].mean()
        std_val = dataset[feature].std()
        print(f"   {feature}: Mean={mean_val:.3f}, Std={std_val:.3f}")
    
    # 4. TESTE DE MÃšLTIPLAS DIVISÃ•ES TEMPORAIS
    print(f"\nðŸ” ETAPA 4: Teste de MÃºltiplas DivisÃµes (Anti-Overfitting)")
    
    # Testando diferentes janelas de teste
    janelas_teste = [10, 15, 20, 25, 30]
    resultados_janelas = []
    
    for janela in janelas_teste:
        if len(dataset) > janela + 50:  # Garantir dados suficientes
            train_data = dataset.iloc[:-janela]
            test_data = dataset.iloc[-janela:]
            
            X_train = train_data[features]
            y_train = train_data['Target']
            X_test = test_data[features]
            y_test = test_data['Target']
            
            modelo = Pipeline([
                ('scaler', StandardScaler()),
                ('clf', VotingClassifier([
                    ('lr', LogisticRegression(C=1.0, random_state=42)),
                    ('rf', RandomForestClassifier(n_estimators=150, max_depth=7, random_state=42))
                ], voting='hard'))
            ])
            
            modelo.fit(X_train, y_train)
            y_pred = modelo.predict(X_test)
            acc = accuracy_score(y_test, y_pred)
            
            baseline = max(y_test.mean(), 1 - y_test.mean())
            
            resultados_janelas.append({
                'janela': janela,
                'acuracia': acc,
                'baseline': baseline,
                'n_test': len(y_test),
                'n_train': len(y_train)
            })
            
            print(f"   Janela {janela:2d} dias: {acc:.1%} (baseline: {baseline:.1%}, n_test: {len(y_test)})")
    
    # 5. VALIDAÃ‡ÃƒO CRUZADA TEMPORAL RIGOROSA
    print(f"\nðŸ” ETAPA 5: ValidaÃ§Ã£o Cruzada Temporal (5 Folds)")
    
    tscv = TimeSeriesSplit(n_splits=5)
    cv_scores = []
    cv_baselines = []
    
    for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
        X_train_cv = X.iloc[train_idx]
        X_test_cv = X.iloc[test_idx]
        y_train_cv = y.iloc[train_idx]
        y_test_cv = y.iloc[test_idx]
        
        modelo_cv = Pipeline([
            ('scaler', StandardScaler()),
            ('clf', VotingClassifier([
                ('lr', LogisticRegression(C=1.0, random_state=42)),
                ('rf', RandomForestClassifier(n_estimators=150, max_depth=7, random_state=42))
            ], voting='hard'))
        ])
        
        modelo_cv.fit(X_train_cv, y_train_cv)
        score = accuracy_score(y_test_cv, modelo_cv.predict(X_test_cv))
        baseline = max(y_test_cv.mean(), 1 - y_test_cv.mean())
        
        cv_scores.append(score)
        cv_baselines.append(baseline)
        
        print(f"   Fold {fold+1}: {score:.1%} (baseline: {baseline:.1%}, test_size: {len(y_test_cv)})")
    
    cv_mean = np.mean(cv_scores)
    cv_std = np.std(cv_scores)
    baseline_mean = np.mean(cv_baselines)
    
    print(f"\nðŸ“Š CV FINAL: {cv_mean:.1%} Â± {cv_std:.1%}")
    print(f"ðŸ“Š BASELINE MÃ‰DIO: {baseline_mean:.1%}")
    
    # 6. TESTE COM MODELO MAIS SIMPLES (BASELINE)
    print(f"\nðŸ” ETAPA 6: ComparaÃ§Ã£o com Modelos Mais Simples")
    
    # Ãšltimo teste como no main
    n_test = 20
    train_data = dataset.iloc[:-n_test]
    test_data = dataset.iloc[-n_test:]
    
    X_train = train_data[features]
    y_train = train_data['Target']
    X_test = test_data[features]
    y_test = test_data['Target']
    
    # Modelo simples (apenas Logistic Regression)
    modelo_simples = Pipeline([
        ('scaler', StandardScaler()),
        ('clf', LogisticRegression(C=1.0, random_state=42))
    ])
    
    modelo_simples.fit(X_train, y_train)
    acc_simples = accuracy_score(y_test, modelo_simples.predict(X_test))
    
    # Modelo complexo (como no main)
    modelo_complexo = Pipeline([
        ('scaler', StandardScaler()),
        ('clf', VotingClassifier([
            ('lr', LogisticRegression(C=1.0, random_state=42)),
            ('rf', RandomForestClassifier(n_estimators=150, max_depth=7, random_state=42))
        ], voting='hard'))
    ])
    
    modelo_complexo.fit(X_train, y_train)
    acc_complexo = accuracy_score(y_test, modelo_complexo.predict(X_test))
    
    baseline_final = max(y_test.mean(), 1 - y_test.mean())
    
    print(f"   Modelo Simples (LogReg): {acc_simples:.1%}")
    print(f"   Modelo Complexo (Ensemble): {acc_complexo:.1%}")
    print(f"   Baseline: {baseline_final:.1%}")
    print(f"   DiferenÃ§a: {(acc_complexo - acc_simples)*100:+.1f} pontos")
    
    # 7. ANÃLISE DE ESTABILIDADE TEMPORAL
    print(f"\nðŸ” ETAPA 7: AnÃ¡lise de Estabilidade Temporal")
    
    # Dividindo em 3 perÃ­odos
    n_total = len(dataset)
    periodo1 = dataset.iloc[:n_total//3]
    periodo2 = dataset.iloc[n_total//3:2*n_total//3]
    periodo3 = dataset.iloc[2*n_total//3:]
    
    print(f"   PerÃ­odo 1: {periodo1['Target'].mean():.1%} positivos")
    print(f"   PerÃ­odo 2: {periodo2['Target'].mean():.1%} positivos")
    print(f"   PerÃ­odo 3: {periodo3['Target'].mean():.1%} positivos")
    
    # 8. DIAGNÃ“STICO FINAL
    print(f"\n" + "="*80)
    print(f"ðŸ† DIAGNÃ“STICO FINAL - DETECÃ‡ÃƒO DE OVERFITTING")
    print(f"="*80)
    
    # CritÃ©rios de overfitting
    overfitting_flags = []
    
    # 1. CV muito diferente do resultado final
    if abs(cv_mean - acc_complexo) > 0.15:  # 15 pontos de diferenÃ§a
        overfitting_flags.append("CV vs Final muito diferente")
    
    # 2. Variabilidade alta no CV
    if cv_std > 0.20:  # 20 pontos de desvio padrÃ£o
        overfitting_flags.append("CV com alta variabilidade")
    
    # 3. Modelo complexo muito melhor que simples
    if (acc_complexo - acc_simples) > 0.20:  # 20 pontos melhor
        overfitting_flags.append("Modelo complexo suspeito")
    
    # 4. Resultado muito acima da mÃ©dia do CV
    if acc_complexo > (cv_mean + 2*cv_std):
        overfitting_flags.append("Resultado final suspeito")
    
    # 5. Poucos dados de teste
    if n_test < 15:
        overfitting_flags.append("Poucos dados de teste")
    
    print(f"ðŸŽ¯ RESULTADO PRINCIPAL: {acc_complexo:.1%}")
    print(f"ðŸ“Š CV MÃ‰DIO: {cv_mean:.1%} Â± {cv_std:.1%}")
    print(f"ðŸ”¢ FEATURES: {len(features)}")
    print(f"ðŸ“Š DADOS DE TESTE: {n_test}")
    print(f"ðŸ“ˆ BASELINE: {baseline_final:.1%}")
    
    print(f"\nðŸš¨ FLAGS DE OVERFITTING:")
    if overfitting_flags:
        for flag in overfitting_flags:
            print(f"   âŒ {flag}")
        print(f"\nâš ï¸ ALERTA: PossÃ­vel overfitting detectado!")
        print(f"ðŸ” RECOMENDAÃ‡ÃƒO: Investigar mais ou usar CV como resultado")
    else:
        print(f"   âœ… Nenhum flag crÃ­tico detectado")
        print(f"   âœ… Resultado parece legÃ­timo")
        print(f"\nðŸ† CONCLUSÃƒO: Pipeline aprovado!")
    
    # Resumo das mÃ©tricas
    print(f"\nðŸ“Š RESUMO DAS MÃ‰TRICAS:")
    print(f"   AcurÃ¡cia Final: {acc_complexo:.1%}")
    print(f"   CV MÃ©dio: {cv_mean:.1%}")
    print(f"   Modelo Simples: {acc_simples:.1%}")
    print(f"   Baseline: {baseline_final:.1%}")
    print(f"   Estabilidade CV: {cv_std:.1%}")
    
    return {
        'acuracia_final': acc_complexo,
        'cv_mean': cv_mean,
        'cv_std': cv_std,
        'modelo_simples': acc_simples,
        'baseline': baseline_final,
        'overfitting_flags': overfitting_flags,
        'n_features': len(features),
        'n_test': n_test,
        'resultados_janelas': resultados_janelas
    }

if __name__ == "__main__":
    resultado = diagnostico_completo()
    
    print(f"\n" + "="*80)
    print(f"ðŸ“‹ RELATÃ“RIO EXECUTIVO - OVERFITTING CHECK")
    print(f"="*80)
    
    if len(resultado['overfitting_flags']) == 0:
        print(f"âœ… PIPELINE APROVADO - SEM OVERFITTING DETECTADO")
        print(f"ðŸŽ¯ Resultado: {resultado['acuracia_final']:.1%} Ã© confiÃ¡vel")
    else:
        print(f"âš ï¸ ATENÃ‡ÃƒO - POSSÃVEL OVERFITTING")
        print(f"ðŸ” Usar CV como referÃªncia: {resultado['cv_mean']:.1%}")
    
    print(f"\nðŸ“Š MÃ‰TRICAS CHAVE:")
    print(f"   Final: {resultado['acuracia_final']:.1%}")
    print(f"   CV: {resultado['cv_mean']:.1%} Â± {resultado['cv_std']:.1%}")
    print(f"   Simples: {resultado['modelo_simples']:.1%}")
    print(f"   Flags: {len(resultado['overfitting_flags'])}")
