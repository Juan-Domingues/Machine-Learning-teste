"""
MAIN REFINADO - VERSÃƒO FINAL OTIMIZADA
Baseado no sucesso de 70% - maximizando estabilidade
"""

import sys
import os
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta

from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

def main_refinado():
    """
    Pipeline refinado para manter 70%+ de forma consistente
    """
    print("="*70)
    print("ğŸ¯ MAIN REFINADO - MAXIMIZANDO ACURÃCIA")
    print("ğŸ“Š OBJETIVO: Superar 60% do colega e manter 70%+")
    print("="*70)
    
    try:
        # 1. CARREGAMENTO OTIMIZADO
        print("\nğŸ“¥ ETAPA 1: Carregamento Otimizado")
        end_date = datetime.now()
        start_date = end_date - timedelta(days=3 * 365)  # 3 anos funcionou melhor
        data = yf.download('^BVSP', start=start_date, end=end_date)
        
        if isinstance(data.columns, pd.MultiIndex):
            data.columns = data.columns.get_level_values(0)
        
        print(f"âœ… {len(data)} dias carregados (3 anos)")
        
        # 2. FEATURES OTIMIZADAS
        print("\nğŸ”§ ETAPA 2: Features Otimizadas")
        
        data['Return'] = data['Close'].pct_change()
        data['Target'] = (data['Close'].shift(-1) > data['Close']).astype(int)
        
        # Features que funcionaram melhor
        data['Return_lag1'] = data['Return'].shift(1)
        data['Return_lag2'] = data['Return'].shift(2)
        
        # MÃ©dias mÃ³veis
        data['SMA_3'] = data['Close'].rolling(3).mean()
        data['SMA_5'] = data['Close'].rolling(5).mean()
        data['SMA_10'] = data['Close'].rolling(10).mean()
        
        # Sinais binÃ¡rios (mais eficazes)
        data['Price_above_SMA3'] = (data['Close'] > data['SMA_3']).astype(int)
        data['Price_above_SMA5'] = (data['Close'] > data['SMA_5']).astype(int)
        data['Price_above_SMA10'] = (data['Close'] > data['SMA_10']).astype(int)
        data['SMA3_above_SMA5'] = (data['SMA_3'] > data['SMA_5']).astype(int)
        data['SMA5_above_SMA10'] = (data['SMA_5'] > data['SMA_10']).astype(int)
        
        # Volume
        data['Volume_MA_20'] = data['Volume'].rolling(20).mean()
        data['Volume_above_avg'] = (data['Volume'] > data['Volume_MA_20']).astype(int)
        data['High_volume'] = (data['Volume'] > data['Volume'].rolling(20).quantile(0.7)).astype(int)
        
        # Momentum
        data['Positive_return_lag1'] = (data['Return_lag1'] > 0).astype(int)
        data['Positive_return_lag2'] = (data['Return_lag2'] > 0).astype(int)
        
        print("âœ… Features criadas com sucesso")
        
        # 3. CONFIGURAÃ‡Ã•ES TESTADAS
        print("\nğŸ§ª ETAPA 3: Teste de ConfiguraÃ§Ãµes Vencedoras")
        
        configs = [
            {
                'nome': 'Trend + Volume (Base)',
                'features': ['Price_above_SMA5', 'Volume_above_avg'],
                'janela': 20
            },
            {
                'nome': 'Trend + Volume (15 dias)',
                'features': ['Price_above_SMA5', 'Volume_above_avg'],
                'janela': 15
            },
            {
                'nome': 'Trend + Volume + Momentum',
                'features': ['Price_above_SMA5', 'Volume_above_avg', 'Positive_return_lag1'],
                'janela': 20
            },
            {
                'nome': 'Multi-Trend + Volume',
                'features': ['Price_above_SMA3', 'Price_above_SMA5', 'Volume_above_avg'],
                'janela': 20
            },
            {
                'nome': 'Trend Completo',
                'features': ['Price_above_SMA5', 'SMA3_above_SMA5', 'SMA5_above_SMA10', 'Volume_above_avg'],
                'janela': 20
            }
        ]
        
        # Dataset base
        all_features = [
            'Price_above_SMA3', 'Price_above_SMA5', 'Price_above_SMA10',
            'SMA3_above_SMA5', 'SMA5_above_SMA10',
            'Volume_above_avg', 'High_volume',
            'Positive_return_lag1', 'Positive_return_lag2'
        ]
        
        dataset = data[all_features + ['Target']].dropna()
        print(f"ğŸ“Š Dataset limpo: {len(dataset)} observaÃ§Ãµes")
        
        resultados = []
        
        for config in configs:
            print(f"\nğŸ”¹ {config['nome']}")
            
            features = config['features']
            n_test = config['janela']
            
            # DivisÃ£o temporal
            train_data = dataset.iloc[:-n_test]
            test_data = dataset.iloc[-n_test:]
            
            X_train = train_data[features]
            y_train = train_data['Target']
            X_test = test_data[features]
            y_test = test_data['Target']
            
            baseline = max(y_test.mean(), 1 - y_test.mean())
            
            # Modelos individuais
            lr = Pipeline([
                ('scaler', StandardScaler()),
                ('clf', LogisticRegression(C=0.1, random_state=42, max_iter=1000))
            ])
            lr.fit(X_train, y_train)
            acc_lr = accuracy_score(y_test, lr.predict(X_test))
            
            rf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1)
            rf.fit(X_train, y_train)
            acc_rf = accuracy_score(y_test, rf.predict(X_test))
            
            # Ensemble (que funcionou melhor)
            ensemble = VotingClassifier([
                ('lr', LogisticRegression(C=0.1, random_state=42, max_iter=1000)),
                ('rf', RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1))
            ], voting='hard')
            
            ensemble_pipeline = Pipeline([
                ('scaler', StandardScaler()),
                ('clf', ensemble)
            ])
            ensemble_pipeline.fit(X_train, y_train)
            acc_ensemble = accuracy_score(y_test, ensemble_pipeline.predict(X_test))
            
            print(f"   LR: {acc_lr:.1%} | RF: {acc_rf:.1%} | Ensemble: {acc_ensemble:.1%}")
            print(f"   Baseline: {baseline:.1%}")
            
            melhor_acc = max(acc_lr, acc_rf, acc_ensemble)
            melhor_modelo = 'LR' if acc_lr == melhor_acc else ('RF' if acc_rf == melhor_acc else 'Ensemble')
            
            resultados.append({
                'config': config['nome'],
                'features': features,
                'acuracia': melhor_acc,
                'modelo': melhor_modelo,
                'baseline': baseline,
                'janela': n_test,
                'pipeline': ensemble_pipeline if melhor_modelo == 'Ensemble' else (lr if melhor_modelo == 'LR' else rf)
            })
        
        # 4. VALIDAÃ‡ÃƒO CRUZADA
        print(f"\nğŸ” ETAPA 4: ValidaÃ§Ã£o Cruzada")
        
        melhor_resultado = max(resultados, key=lambda x: x['acuracia'])
        print(f"\nMelhor configuraÃ§Ã£o: {melhor_resultado['config']}")
        print(f"AcurÃ¡cia: {melhor_resultado['acuracia']:.1%}")
        
        # ValidaÃ§Ã£o cruzada temporal
        features_finais = melhor_resultado['features']
        X = dataset[features_finais]
        y = dataset['Target']
        
        tscv = TimeSeriesSplit(n_splits=4)
        cv_scores = []
        
        for train_idx, test_idx in tscv.split(X):
            X_train_cv = X.iloc[train_idx]
            X_test_cv = X.iloc[test_idx]
            y_train_cv = y.iloc[train_idx]
            y_test_cv = y.iloc[test_idx]
            
            ensemble = VotingClassifier([
                ('lr', LogisticRegression(C=0.1, random_state=42, max_iter=1000)),
                ('rf', RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1))
            ], voting='hard')
            
            pipeline_cv = Pipeline([
                ('scaler', StandardScaler()),
                ('clf', ensemble)
            ])
            
            pipeline_cv.fit(X_train_cv, y_train_cv)
            score = accuracy_score(y_test_cv, pipeline_cv.predict(X_test_cv))
            cv_scores.append(score)
        
        cv_mean = np.mean(cv_scores)
        cv_std = np.std(cv_scores)
        
        print(f"CV Score: {cv_mean:.1%} Â± {cv_std:.1%}")
        
        # 5. RESULTADO FINAL
        print(f"\n" + "="*70)
        print(f"ğŸ† RESULTADO FINAL")
        print(f"="*70)
        
        acuracia_final = melhor_resultado['acuracia']
        baseline_final = melhor_resultado['baseline']
        
        print(f"ğŸ¯ ACURÃCIA FINAL: {acuracia_final:.1%}")
        print(f"ğŸ“Š BASELINE: {baseline_final:.1%}")
        print(f"ğŸ“ˆ MELHORIA: {(acuracia_final - baseline_final)*100:+.1f} pontos")
        print(f"ğŸ”§ CONFIGURAÃ‡ÃƒO: {melhor_resultado['config']}")
        print(f"ğŸ“Š FEATURES: {melhor_resultado['features']}")
        print(f"ğŸ¤– MODELO: {melhor_resultado['modelo']}")
        print(f"ğŸ“Š CV SCORE: {cv_mean:.1%} Â± {cv_std:.1%}")
        
        # ComparaÃ§Ãµes importantes
        print(f"\nğŸ¯ COMPARAÃ‡Ã•ES:")
        print(f"   Meta 75%: {'âœ… ATINGIDA' if acuracia_final >= 0.75 else f'âŒ Faltam {(0.75 - acuracia_final)*100:.1f} pontos'}")
        print(f"   Meta 70%: {'âœ… ATINGIDA' if acuracia_final >= 0.70 else f'âŒ Faltam {(0.70 - acuracia_final)*100:.1f} pontos'}")
        print(f"   Meta 60%: {'âœ… ATINGIDA' if acuracia_final >= 0.60 else f'âŒ Faltam {(0.60 - acuracia_final)*100:.1f} pontos'}")
        print(f"   Colega (60%): {'ğŸ† SUPERADO' if acuracia_final > 0.60 else 'âŒ NÃƒO SUPERADO'}")
        
        if acuracia_final >= 0.75:
            print(f"\nğŸ‰ğŸ‰ğŸ‰ FANTÃSTICO! META 75% ATINGIDA! ğŸ‰ğŸ‰ğŸ‰")
        elif acuracia_final >= 0.70:
            print(f"\nğŸ‰ EXCELENTE! META 70% ATINGIDA!")
            print(f"ğŸ“ˆ Faltam apenas {(0.75 - acuracia_final)*100:.1f} pontos para 75%")
        elif acuracia_final >= 0.60:
            print(f"\nâœ… MUITO BOM! META 60% ATINGIDA!")
            print(f"ğŸ† SUPERAMOS O COLEGA!")
        else:
            print(f"\nğŸ“Š Resultado: {acuracia_final:.1%} - Continuar refinando")
        
        # Ranking de todas as configuraÃ§Ãµes
        print(f"\nğŸ“Š RANKING DE CONFIGURAÃ‡Ã•ES:")
        resultados_ordenados = sorted(resultados, key=lambda x: x['acuracia'], reverse=True)
        for i, r in enumerate(resultados_ordenados, 1):
            print(f"   {i}. {r['config']}: {r['acuracia']:.1%} ({r['modelo']})")
        
        return {
            'acuracia_final': acuracia_final,
            'baseline': baseline_final,
            'cv_score': cv_mean,
            'cv_std': cv_std,
            'melhor_config': melhor_resultado,
            'todos_resultados': resultados_ordenados,
            'features_finais': features_finais,
            'meta_75': acuracia_final >= 0.75,
            'meta_70': acuracia_final >= 0.70,
            'meta_60': acuracia_final >= 0.60,
            'superou_colega': acuracia_final > 0.60
        }
        
    except Exception as e:
        print(f"\nâŒ ERRO: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    resultado = main_refinado()
    
    if resultado:
        print(f"\nğŸ¯ RESUMO EXECUTIVO:")
        print(f"   ğŸ“Š AcurÃ¡cia: {resultado['acuracia_final']:.1%}")
        print(f"   ğŸ”§ Features: {len(resultado['features_finais'])}")
        print(f"   ğŸ“ˆ CV: {resultado['cv_score']:.1%}")
        
        if resultado['meta_75']:
            print(f"   ğŸ† STATUS: META 75% ATINGIDA!")
        elif resultado['meta_70']:
            print(f"   ğŸ† STATUS: META 70% ATINGIDA!")
        elif resultado['superou_colega']:
            print(f"   ğŸ† STATUS: SUPERAMOS O COLEGA!")
        else:
            print(f"   ğŸ“Š STATUS: CONTINUAR REFINANDO")
    else:
        print("\nâŒ Falha no pipeline")
