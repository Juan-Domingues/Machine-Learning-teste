"""
Machine Learning Aplicado ao IBOVESPA - AnÃ¡lise Completa com ValidaÃ§Ã£o Cruzada
Baseado nos conceitos fundamentais do curso:
- Linear Regression
- Diferentes tÃ©cnicas de normalizaÃ§Ã£o/padronizaÃ§Ã£o
- ValidaÃ§Ã£o Cruzada
- ComparaÃ§Ã£o de performance
- Pipeline de Machine Learning
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Imports do Scikit-Learn
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer

# ConfiguraÃ§Ã£o para grÃ¡ficos mais bonitos
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class MLIbovespaValidacaoCruzada:
    """
    Classe para testar diferentes tÃ©cnicas de normalizaÃ§Ã£o com validaÃ§Ã£o cruzada
    no modelo Linear Regression aplicado ao IBOVESPA
    """
    
    def __init__(self):
        self.data = None
        self.X = None
        self.y = None
        self.resultados = {}
        
    def carregar_dados(self, anos=10):
        """
        1. CARREGAMENTO DE DADOS
        Baixa dados reais do IBOVESPA via Yahoo Finance
        Incluindo perÃ­odo do Plano Real para maior robustez
        """
        print("="*50)
        print("1. CARREGANDO DADOS DO IBOVESPA")
        print("="*50)
        
        # Definir perÃ­odo
        end_date = datetime.now()
        start_date = end_date - timedelta(days=anos * 365)
        
        print(f"ğŸ“Š Baixando dados de {start_date.strftime('%Y-%m-%d')} atÃ© {end_date.strftime('%Y-%m-%d')}")
        print(f"ğŸ—“ï¸ PerÃ­odo: {anos} anos de dados (incluindo era Plano Real)")
        print("ğŸ’¡ Dados histÃ³ricos extensos para validaÃ§Ã£o cruzada robusta")
        
        # Baixar dados
        self.data = yf.download('^BVSP', start=start_date, end=end_date)
        
        # Limpar colunas se necessÃ¡rio
        if isinstance(self.data.columns, pd.MultiIndex):
            self.data.columns = self.data.columns.get_level_values(0)
        
        print(f"âœ… {len(self.data)} dias de dados carregados")
        print(f"ğŸ“ˆ PreÃ§o atual: R$ {self.data['Close'].iloc[-1]:,.2f}")
        
        return self.data
    
    def engenharia_features(self):
        """
        2. ENGENHARIA DE FEATURES
        CriaÃ§Ã£o de indicadores tÃ©cnicos simples
        """
        print("\n" + "="*50)
        print("2. CRIANDO FEATURES (INDICADORES TÃ‰CNICOS)")
        print("="*50)
        
        # Calcular retornos
        self.data['Retorno'] = self.data['Close'].pct_change()
        
        # MÃ©dias mÃ³veis
        self.data['MM5'] = self.data['Close'].rolling(window=5).mean()
        self.data['MM20'] = self.data['Close'].rolling(window=20).mean()
        self.data['MM50'] = self.data['Close'].rolling(window=50).mean()
        
        # RSI simplificado
        delta = self.data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        self.data['RSI'] = 100 - (100 / (1 + rs))
        
        # Volatilidade
        self.data['Volatilidade'] = self.data['Retorno'].rolling(window=20).std()
        
        # Volume normalizado
        self.data['Volume_Norm'] = self.data['Volume'] / self.data['Volume'].rolling(window=20).mean()
        
        # MÃ¡ximos e mÃ­nimos
        self.data['Max_20'] = self.data['High'].rolling(window=20).max()
        self.data['Min_20'] = self.data['Low'].rolling(window=20).min()
        self.data['Posicao_Canal'] = (self.data['Close'] - self.data['Min_20']) / (self.data['Max_20'] - self.data['Min_20'])
        
        # Features avanÃ§adas
        self.data['Momentum_3'] = self.data['Close'] / self.data['Close'].shift(3) - 1
        self.data['Momentum_7'] = self.data['Close'] / self.data['Close'].shift(7) - 1
        self.data['Momentum_14'] = self.data['Close'] / self.data['Close'].shift(14) - 1
        
        self.data['Volatilidade_5'] = self.data['Retorno'].rolling(5).std()
        self.data['Vol_Ratio'] = self.data['Volatilidade_5'] / self.data['Volatilidade']
        
        self.data['MM_Ratio_5_20'] = self.data['MM5'] / self.data['MM20']
        self.data['MM_Ratio_20_50'] = self.data['MM20'] / self.data['MM50']
        self.data['Distancia_MM20'] = (self.data['Close'] - self.data['MM20']) / self.data['MM20']
        
        self.data['Canal_Width'] = (self.data['Max_20'] - self.data['Min_20']) / self.data['Close']
        self.data['Retorno_Acum_3'] = self.data['Retorno'].rolling(3).sum()
        self.data['Retorno_Acum_7'] = self.data['Retorno'].rolling(7).sum()
        
        print("âœ… Features criadas (bÃ¡sicas + avanÃ§adas)")
        
        return self.data
    
    def criar_target(self):
        """
        3. CRIAR VARIÃVEL TARGET
        Retorno futuro de 1 dia (REGRESSÃƒO)
        """
        print("\n" + "="*50)
        print("3. CRIANDO TARGET (RETORNO FUTURO)")
        print("="*50)
        
        # Target: retorno do prÃ³ximo dia
        self.data['Target'] = self.data['Retorno'].shift(-1)
        
        print("âœ… Target criado: Retorno do prÃ³ximo dia")
        print(f"ğŸ“Š DistribuiÃ§Ã£o do target:")
        print(self.data['Target'].describe())
        
        return self.data
    
    def selecionar_melhores_features(self, max_features=10):
        """
        4. SELEÃ‡ÃƒO DAS MELHORES FEATURES
        """
        print("\n" + "="*60)
        print("4. SELEÃ‡ÃƒO DAS MELHORES FEATURES")
        print("="*60)
        
        # Todas as features disponÃ­veis
        todas_features = [
            'MM5', 'MM20', 'MM50', 'RSI', 'Volatilidade', 'Volume_Norm', 'Posicao_Canal',
            'Momentum_3', 'Momentum_7', 'Momentum_14',
            'Volatilidade_5', 'Vol_Ratio', 
            'MM_Ratio_5_20', 'MM_Ratio_20_50', 'Distancia_MM20',
            'Canal_Width', 'Retorno_Acum_3', 'Retorno_Acum_7'
        ]
        
        # Preparar dataset
        dataset = self.data[todas_features + ['Target']].dropna()
        
        # Calcular correlaÃ§Ãµes absolutas
        correlacoes = dataset[todas_features].corrwith(dataset['Target']).abs().sort_values(ascending=False)
        
        # Selecionar top features
        melhores_features = correlacoes.head(max_features).index.tolist()
        
        print(f"ğŸ† Top {max_features} Features selecionadas:")
        for i, (feat, corr) in enumerate(correlacoes.head(max_features).items(), 1):
            simbolo = "ğŸ”´" if corr > 0.1 else "ğŸŸ¡" if corr > 0.05 else "ğŸŸ¢"
            print(f"   {i:2d}. {simbolo} {feat}: {corr:.4f}")
        
        # Preparar dataset final
        self.X = dataset[melhores_features]
        self.y = dataset['Target']
        
        print(f"\nâœ… Dataset preparado:")
        print(f"ğŸ“Š {len(self.X)} observaÃ§Ãµes")
        print(f"ğŸ“Š {len(melhores_features)} features selecionadas")
        
        return melhores_features
    
    def validacao_cruzada_completa(self, cv_folds=5):
        """
        5. VALIDAÃ‡ÃƒO CRUZADA COMPLETA
        Testa diferentes scalers com validaÃ§Ã£o cruzada
        """
        print("\n" + "="*70)
        print("ğŸ”„ VALIDAÃ‡ÃƒO CRUZADA - COMPARAÃ‡ÃƒO DE SCALERS")
        print(f"ğŸ¯ K-Fold: {cv_folds} folds")
        print("ğŸ¯ DivisÃ£o temporal preservada")
        print("="*70)
        
        # Diferentes tipos de scalers
        scalers = {
            'Sem NormalizaÃ§Ã£o': None,
            'StandardScaler': StandardScaler(),
            'MinMaxScaler': MinMaxScaler(),
            'RobustScaler': RobustScaler(),
            'Normalizer': Normalizer()
        }
        
        # FunÃ§Ã£o personalizada para calcular acurÃ¡cia de direÃ§Ã£o
        def acuracia_direcao(y_true, y_pred):
            y_true_dir = (y_true > 0).astype(int)
            y_pred_dir = (y_pred > 0).astype(int)
            return np.mean(y_true_dir == y_pred_dir)
        
        # Criar scorer personalizado
        scorer_acuracia = make_scorer(acuracia_direcao)
        
        resultados_cv = {}
        
        for nome_scaler, scaler in scalers.items():
            print(f"\nğŸ§ª ValidaÃ§Ã£o cruzada: {nome_scaler}")
            print("-" * 50)
            
            try:
                # Criar pipeline
                if scaler is None:
                    modelo = LinearRegression()
                else:
                    modelo = Pipeline([
                        ('scaler', scaler),
                        ('regressor', LinearRegression())
                    ])
                
                # ValidaÃ§Ã£o cruzada para acurÃ¡cia de direÃ§Ã£o
                scores_acuracia = cross_val_score(
                    modelo, self.X, self.y, 
                    cv=cv_folds, 
                    scoring=scorer_acuracia,
                    n_jobs=-1
                )
                
                # ValidaÃ§Ã£o cruzada para RÂ²
                scores_r2 = cross_val_score(
                    modelo, self.X, self.y, 
                    cv=cv_folds, 
                    scoring='r2',
                    n_jobs=-1
                )
                
                # Armazenar resultados
                resultados_cv[nome_scaler] = {
                    'acuracia_scores': scores_acuracia,
                    'acuracia_mean': scores_acuracia.mean(),
                    'acuracia_std': scores_acuracia.std(),
                    'r2_scores': scores_r2,
                    'r2_mean': scores_r2.mean(),
                    'r2_std': scores_r2.std()
                }
                
                # Exibir resultados
                print(f"ğŸ“Š AcurÃ¡cia CV: {scores_acuracia.mean():.1%} (Â±{scores_acuracia.std():.1%})")
                print(f"ğŸ“Š RÂ² CV: {scores_r2.mean():.4f} (Â±{scores_r2.std():.4f})")
                print(f"ğŸ“Š Folds acurÃ¡cia: {[f'{s:.1%}' for s in scores_acuracia]}")
                
                qualidade = "âœ… Excelente" if scores_acuracia.mean() >= 0.6 else "âœ… SatisfatÃ³ria" if scores_acuracia.mean() >= 0.55 else "âš ï¸ Pode melhorar"
                print(f"ğŸ“ˆ Qualidade: {qualidade}")
                
            except Exception as e:
                print(f"âŒ Erro com {nome_scaler}: {e}")
                continue
        
        return resultados_cv
    
    def teste_holdout(self):
        """
        6. TESTE HOLDOUT (70/30)
        Para comparaÃ§Ã£o com validaÃ§Ã£o cruzada
        """
        print("\n" + "="*70)
        print("ğŸ§ª TESTE HOLDOUT - COMPARAÃ‡ÃƒO DE SCALERS")
        print("ğŸ¯ DivisÃ£o: 70% Treino / 30% Teste")
        print("="*70)
        
        # DivisÃ£o dos dados
        X_treino, X_teste, y_treino, y_teste = train_test_split(
            self.X, self.y, test_size=0.3, random_state=42, shuffle=False
        )
        
        print(f"ğŸ“Š DivisÃ£o dos dados:")
        print(f"   ğŸ“ Treino: {len(X_treino)} observaÃ§Ãµes (70%)")
        print(f"   ğŸ§ª Teste: {len(X_teste)} observaÃ§Ãµes (30%)")
        
        # Diferentes tipos de scalers
        scalers = {
            'Sem NormalizaÃ§Ã£o': None,
            'StandardScaler': StandardScaler(),
            'MinMaxScaler': MinMaxScaler(),
            'RobustScaler': RobustScaler(),
            'Normalizer': Normalizer()
        }
        
        resultados_holdout = {}
        
        for nome_scaler, scaler in scalers.items():
            print(f"\nğŸ§ª Testando: {nome_scaler}")
            print("-" * 40)
            
            try:
                # Criar pipeline
                if scaler is None:
                    modelo = LinearRegression()
                    X_treino_scaled = X_treino
                    X_teste_scaled = X_teste
                else:
                    modelo = Pipeline([
                        ('scaler', scaler),
                        ('regressor', LinearRegression())
                    ])
                    X_treino_scaled = X_treino
                    X_teste_scaled = X_teste
                
                # Treinar modelo
                modelo.fit(X_treino_scaled, y_treino)
                
                # Fazer previsÃµes
                y_pred = modelo.predict(X_teste_scaled)
                
                # Calcular mÃ©tricas
                r2 = r2_score(y_teste, y_pred)
                rmse = np.sqrt(mean_squared_error(y_teste, y_pred))
                mae = mean_absolute_error(y_teste, y_pred)
                
                # Calcular acurÃ¡cia de direÃ§Ã£o
                y_teste_direcao = (y_teste > 0).astype(int)
                y_pred_direcao = (y_pred > 0).astype(int)
                acuracia = np.mean(y_teste_direcao == y_pred_direcao)
                
                # Armazenar resultados
                resultados_holdout[nome_scaler] = {
                    'r2': r2,
                    'rmse': rmse,
                    'mae': mae,
                    'acuracia': acuracia
                }
                
                # Exibir resultados
                print(f"ğŸ“Š RÂ²: {r2:.4f}")
                print(f"ğŸ“Š RMSE: {rmse:.4f}")
                print(f"ğŸ“Š MAE: {mae:.4f}")
                print(f"ğŸ¯ AcurÃ¡cia: {acuracia:.1%}")
                
                qualidade = "âœ… Excelente" if acuracia >= 0.6 else "âœ… SatisfatÃ³ria" if acuracia >= 0.55 else "âš ï¸ Pode melhorar"
                print(f"ğŸ“ˆ Qualidade: {qualidade}")
                
            except Exception as e:
                print(f"âŒ Erro com {nome_scaler}: {e}")
                continue
        
        return resultados_holdout
    
    def executar_analise_completa(self):
        """
        Executa anÃ¡lise completa com validaÃ§Ã£o cruzada
        """
        try:
            # 1-4: PreparaÃ§Ã£o dos dados
            self.carregar_dados()
            self.engenharia_features()
            self.criar_target()
            melhores_features = self.selecionar_melhores_features()
            
            # 5: ValidaÃ§Ã£o cruzada
            resultados_cv = self.validacao_cruzada_completa()
            
            # 6: Teste holdout para comparaÃ§Ã£o
            resultados_holdout = self.teste_holdout()
            
            # AnÃ¡lise comparativa
            print("\n" + "="*70)
            print("ğŸ“Š ANÃLISE COMPARATIVA: VALIDAÃ‡ÃƒO CRUZADA vs HOLDOUT")
            print("="*70)
            
            # Ranking validaÃ§Ã£o cruzada
            ranking_cv = sorted(resultados_cv.items(), 
                               key=lambda x: x[1]['acuracia_mean'], reverse=True)
            
            # Ranking holdout
            ranking_holdout = sorted(resultados_holdout.items(), 
                                    key=lambda x: x[1]['acuracia'], reverse=True)
            
            print("ğŸ”„ VALIDAÃ‡ÃƒO CRUZADA (Ranking):")
            for i, (nome, metricas) in enumerate(ranking_cv, 1):
                print(f"   {i}Âº {nome}: {metricas['acuracia_mean']:.1%} (Â±{metricas['acuracia_std']:.1%})")
            
            print("\nğŸ§ª HOLDOUT (Ranking):")
            for i, (nome, metricas) in enumerate(ranking_holdout, 1):
                print(f"   {i}Âº {nome}: {metricas['acuracia']:.1%}")
            
            # Melhor configuraÃ§Ã£o
            melhor_cv_nome = ranking_cv[0][0]
            melhor_cv = ranking_cv[0][1]
            melhor_holdout_nome = ranking_holdout[0][0]
            melhor_holdout = ranking_holdout[0][1]
            
            # Resumo final
            print("\n" + "="*50)
            print("ğŸ¯ RESUMO FINAL")
            print("="*50)
            print(f"ğŸ“Š Dataset: {len(self.X)} observaÃ§Ãµes do IBOVESPA")
            print(f"ğŸ“Š Features: {len(melhores_features)} selecionadas")
            
            print(f"\nğŸ”„ VALIDAÃ‡ÃƒO CRUZADA (5-Fold):")
            print(f"ğŸ† Melhor: {melhor_cv_nome}")
            print(f"ğŸ¯ AcurÃ¡cia: {melhor_cv['acuracia_mean']:.1%} (Â±{melhor_cv['acuracia_std']:.1%})")
            print(f"ğŸ“Š RÂ²: {melhor_cv['r2_mean']:.4f} (Â±{melhor_cv['r2_std']:.4f})")
            
            print(f"\nğŸ§ª HOLDOUT (70/30):")
            print(f"ğŸ† Melhor: {melhor_holdout_nome}")
            print(f"ğŸ¯ AcurÃ¡cia: {melhor_holdout['acuracia']:.1%}")
            print(f"ğŸ“Š RÂ²: {melhor_holdout['r2']:.4f}")
            
            # AnÃ¡lise de consistÃªncia
            diff_acuracia = melhor_holdout['acuracia'] - melhor_cv['acuracia_mean']
            print(f"\nğŸ“ˆ CONSISTÃŠNCIA:")
            print(f"ğŸ”€ DiferenÃ§a Holdout vs CV: {diff_acuracia:+.1%}")
            
            if abs(diff_acuracia) < 0.02:
                print("âœ… Resultados consistentes entre mÃ©todos!")
            elif diff_acuracia > 0.02:
                print("âš ï¸ PossÃ­vel overfitting (holdout muito superior)")
            else:
                print("âš ï¸ Holdout pode ter sido pessimista")
            
            # Intervalo de confianÃ§a
            ic_inf = melhor_cv['acuracia_mean'] - 1.96 * melhor_cv['acuracia_std']
            ic_sup = melhor_cv['acuracia_mean'] + 1.96 * melhor_cv['acuracia_std']
            print(f"ğŸ“Š IC 95% (CV): [{ic_inf:.1%}, {ic_sup:.1%}]")
            
            estabilidade = "âœ… Excelente" if melhor_cv['acuracia_std'] < 0.02 else "âœ… Boa" if melhor_cv['acuracia_std'] < 0.05 else "âš ï¸ VariÃ¡vel"
            print(f"ğŸ“Š Estabilidade: {estabilidade}")
            
            qualidade_final = "âœ… Excelente" if melhor_cv['acuracia_mean'] >= 0.6 else "âœ… SatisfatÃ³ria" if melhor_cv['acuracia_mean'] >= 0.55 else "âš ï¸ Pode melhorar"
            print(f"ğŸ“ˆ Qualidade final: {qualidade_final}")
            
            print("\nâœ… AnÃ¡lise completa com validaÃ§Ã£o cruzada concluÃ­da!")
            
            return {
                'cv_results': resultados_cv,
                'holdout_results': resultados_holdout,
                'melhor_cv': melhor_cv_nome,
                'melhor_holdout': melhor_holdout_nome,
                'features_selecionadas': melhores_features,
                'acuracia_cv': melhor_cv['acuracia_mean'],
                'acuracia_holdout': melhor_holdout['acuracia']
            }
            
        except Exception as e:
            print(f"âŒ Erro durante a execuÃ§Ã£o: {e}")
            return None


def main():
    """
    FunÃ§Ã£o principal
    """
    print("ğŸ“š MACHINE LEARNING - LINEAR REGRESSION NO IBOVESPA")
    print("ğŸ”„ ANÃLISE COM VALIDAÃ‡ÃƒO CRUZADA")
    print("ğŸ¯ ConfiguraÃ§Ã£o: 10 anos + K-Fold 5 + Holdout 70/30")
    print("ğŸ’¡ Dados do Plano Real para robustez histÃ³rica")
    print("=" * 70)
    
    # Executar anÃ¡lise
    ml = MLIbovespaValidacaoCruzada()
    resultados = ml.executar_analise_completa()
    
    if resultados:
        print(f"\nğŸ‰ AnÃ¡lise completa concluÃ­da!")
        print(f"\nğŸ“Š RESUMO EXECUTIVO:")
        print(f"ğŸ”„ Melhor CV: {resultados['melhor_cv']}")
        print(f"ğŸ¯ AcurÃ¡cia CV: {resultados['acuracia_cv']:.1%}")
        print(f"ğŸ§ª Melhor Holdout: {resultados['melhor_holdout']}")
        print(f"ğŸ¯ AcurÃ¡cia Holdout: {resultados['acuracia_holdout']:.1%}")
        print(f"ğŸ“Š Features: {len(resultados['features_selecionadas'])} otimizadas")
    else:
        print("\nâŒ AnÃ¡lise nÃ£o foi concluÃ­da devido a erros.")
    
    return ml, resultados


if __name__ == "__main__":
    modelo, resultados = main()
