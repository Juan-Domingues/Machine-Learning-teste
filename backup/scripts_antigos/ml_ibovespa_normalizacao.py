"""
Machine Learning Aplicado ao IBOVESPA - Teste de NormalizaÃ§Ã£o
Baseado nos conceitos fundamentais do curso:
- Linear Regression
- Diferentes tÃ©cnicas de normalizaÃ§Ã£o/padronizaÃ§Ã£o
- ComparaÃ§Ã£o de performance
- Pipeline de Machine Learning
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Imports do Scikit-Learn
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ConfiguraÃ§Ã£o para grÃ¡ficos mais bonitos
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class MLIbovespaNormalizacao:
    """
    Classe para testar diferentes tÃ©cnicas de normalizaÃ§Ã£o
    no modelo Linear Regression aplicado ao IBOVESPA
    """
    
    def __init__(self):
        self.data = None
        self.X = None
        self.y = None
        self.resultados = {}
        
    def carregar_dados(self, anos=10):
        """
        1. CARREGAMENTO DE DADOS
        Baixa dados reais do IBOVESPA via Yahoo Finance
        Incluindo perÃ­odo do Plano Real para maior robustez
        """
        print("="*50)
        print("1. CARREGANDO DADOS DO IBOVESPA")
        print("="*50)
        
        # Definir perÃ­odo
        end_date = datetime.now()
        start_date = end_date - timedelta(days=anos * 365)
        
        print(f"ğŸ“Š Baixando dados de {start_date.strftime('%Y-%m-%d')} atÃ© {end_date.strftime('%Y-%m-%d')}")
        print(f"ğŸ—“ï¸ PerÃ­odo: {anos} anos de dados (incluindo era Plano Real)")
        print("ğŸ’¡ Dados histÃ³ricos extensos para melhor aprendizado de padrÃµes")
        
        # Baixar dados
        self.data = yf.download('^BVSP', start=start_date, end=end_date)
        
        # Limpar colunas se necessÃ¡rio
        if isinstance(self.data.columns, pd.MultiIndex):
            self.data.columns = self.data.columns.get_level_values(0)
        
        print(f"âœ… {len(self.data)} dias de dados carregados")
        print(f"ğŸ“ˆ PreÃ§o atual: R$ {self.data['Close'].iloc[-1]:,.2f}")
        
        return self.data
    
    def engenharia_features(self):
        """
        2. ENGENHARIA DE FEATURES
        CriaÃ§Ã£o de indicadores tÃ©cnicos simples
        """
        print("\n" + "="*50)
        print("2. CRIANDO FEATURES (INDICADORES TÃ‰CNICOS)")
        print("="*50)
        
        # Calcular retornos
        self.data['Retorno'] = self.data['Close'].pct_change()
        
        # MÃ©dias mÃ³veis
        self.data['MM5'] = self.data['Close'].rolling(window=5).mean()
        self.data['MM20'] = self.data['Close'].rolling(window=20).mean()
        self.data['MM50'] = self.data['Close'].rolling(window=50).mean()
        
        # RSI simplificado
        delta = self.data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        self.data['RSI'] = 100 - (100 / (1 + rs))
        
        # Volatilidade
        self.data['Volatilidade'] = self.data['Retorno'].rolling(window=20).std()
        
        # Volume normalizado
        self.data['Volume_Norm'] = self.data['Volume'] / self.data['Volume'].rolling(window=20).mean()
        
        # MÃ¡ximos e mÃ­nimos
        self.data['Max_20'] = self.data['High'].rolling(window=20).max()
        self.data['Min_20'] = self.data['Low'].rolling(window=20).min()
        self.data['Posicao_Canal'] = (self.data['Close'] - self.data['Min_20']) / (self.data['Max_20'] - self.data['Min_20'])
        
        print("âœ… Features criadas:")
        features = ['Retorno', 'MM5', 'MM20', 'MM50', 'RSI', 'Volatilidade', 'Volume_Norm', 'Posicao_Canal']
        for feat in features:
            print(f"   ğŸ“Š {feat}")
        
        return self.data
    
    def criar_target(self):
        """
        3. CRIAR VARIÃVEL TARGET
        Retorno futuro de 1 dia (REGRESSÃƒO)
        """
        print("\n" + "="*50)
        print("3. CRIANDO TARGET (RETORNO FUTURO)")
        print("="*50)
        
        # Target: retorno do prÃ³ximo dia
        self.data['Target'] = self.data['Retorno'].shift(-1)
        
        print("âœ… Target criado: Retorno do prÃ³ximo dia")
        print(f"ğŸ“Š DistribuiÃ§Ã£o do target:")
        print(self.data['Target'].describe())
        
        return self.data
    
    def preparar_dataset(self, features=None):
        """
        4. PREPARAR DATASET FINAL
        """
        print("\n" + "="*50)
        print("4. PREPARANDO DATASET FINAL")
        print("="*50)
        
        # Usar features fornecidas ou padrÃ£o
        if features is None:
            features = ['MM5', 'MM20', 'MM50', 'RSI', 'Volatilidade', 'Volume_Norm', 'Posicao_Canal']
        
        # Criar dataset
        dataset = self.data[features + ['Target']].copy()
        
        # Remover valores nulos
        dataset = dataset.dropna()
        
        # Separar X e y
        self.X = dataset[features]
        self.y = dataset['Target']
        
        print(f"âœ… Dataset preparado:")
        print(f"ğŸ“Š {len(self.X)} observaÃ§Ãµes")
        print(f"ğŸ“Š {len(features)} features")
        print(f"ğŸ“Š Target: {self.y.name}")
        
        return self.X, self.y
    
    def comparar_normalizacao(self, features=None):
        """
        Compara diferentes tÃ©cnicas de normalizaÃ§Ã£o/padronizaÃ§Ã£o
        Usando divisÃ£o 70% treino / 30% teste conforme orientaÃ§Ã£o do professor
        """
        print("\n" + "="*70)
        print("ğŸ”¬ TESTE DE NORMALIZAÃ‡ÃƒO - COMPARAÃ‡ÃƒO DE SCALERS")
        print("ğŸ¯ DivisÃ£o: 70% Treino / 30% Teste (orientaÃ§Ã£o professor)")
        print("="*70)
        
        # Preparar dados
        X, y = self.preparar_dataset(features)
        X_treino, X_teste, y_treino, y_teste = train_test_split(
            X, y, test_size=0.3, random_state=42, shuffle=False
        )
        
        print(f"ğŸ“Š DivisÃ£o dos dados:")
        print(f"   ğŸ“ Treino: {len(X_treino)} observaÃ§Ãµes (70%)")
        print(f"   ğŸ§ª Teste: {len(X_teste)} observaÃ§Ãµes (30%)")
        
        # Diferentes tipos de scalers
        scalers = {
            'Sem NormalizaÃ§Ã£o': None,
            'StandardScaler': StandardScaler(),
            'MinMaxScaler': MinMaxScaler(),
            'RobustScaler': RobustScaler(),
            'Normalizer': Normalizer()
        }
        
        resultados_normalizacao = {}
        
        for nome_scaler, scaler in scalers.items():
            print(f"\nğŸ§ª Testando: {nome_scaler}")
            print("-" * 40)
            
            try:
                # Criar pipeline
                if scaler is None:
                    modelo = LinearRegression()
                    X_treino_scaled = X_treino
                    X_teste_scaled = X_teste
                else:
                    pipeline = Pipeline([
                        ('scaler', scaler),
                        ('regressor', LinearRegression())
                    ])
                    modelo = pipeline
                    X_treino_scaled = X_treino
                    X_teste_scaled = X_teste
                
                # Treinar modelo
                modelo.fit(X_treino_scaled, y_treino)
                
                # Fazer previsÃµes
                y_pred = modelo.predict(X_teste_scaled)
                
                # Calcular mÃ©tricas de regressÃ£o
                r2 = r2_score(y_teste, y_pred)
                rmse = np.sqrt(mean_squared_error(y_teste, y_pred))
                mae = mean_absolute_error(y_teste, y_pred)
                
                # Calcular acurÃ¡cia de direÃ§Ã£o
                y_teste_direcao = (y_teste > 0).astype(int)
                y_pred_direcao = (y_pred > 0).astype(int)
                acuracia = np.mean(y_teste_direcao == y_pred_direcao)
                
                # Armazenar resultados
                resultados_normalizacao[nome_scaler] = {
                    'r2': r2,
                    'rmse': rmse,
                    'mae': mae,
                    'acuracia': acuracia
                }
                
                # Exibir resultados
                print(f"ğŸ“Š RÂ²: {r2:.4f}")
                print(f"ğŸ“Š RMSE: {rmse:.4f}")
                print(f"ğŸ“Š MAE: {mae:.4f}")
                print(f"ğŸ¯ AcurÃ¡cia: {acuracia:.1%}")
                
                qualidade = "âœ… Excelente" if acuracia >= 0.6 else "âœ… SatisfatÃ³ria" if acuracia >= 0.55 else "âš ï¸ Pode melhorar"
                print(f"ğŸ“ˆ Qualidade: {qualidade}")
                
            except Exception as e:
                print(f"âŒ Erro com {nome_scaler}: {e}")
                continue
        
        # Encontrar melhor scaler
        print("\n" + "="*70)
        print("ğŸ† RANKING DOS SCALERS - ORDENADO POR ACURÃCIA")
        print("="*70)
        
        # Ordenar por acurÃ¡cia
        ranking = sorted(resultados_normalizacao.items(), 
                        key=lambda x: x[1]['acuracia'], reverse=True)
        
        for i, (nome, metricas) in enumerate(ranking, 1):
            if nome in resultados_normalizacao:
                print(f"{i}Âº ğŸ¥‡ {nome}:")
                print(f"   ğŸ¯ AcurÃ¡cia: {metricas['acuracia']:.1%}")
                print(f"   ğŸ“Š RÂ²: {metricas['r2']:.4f}")
                print(f"   ğŸ“Š RMSE: {metricas['rmse']:.4f}")
                print(f"   ğŸ“Š MAE: {metricas['mae']:.4f}")
                print()
        
        # Resumo final
        melhor_scaler = ranking[0][0]
        melhores_metricas = ranking[0][1]
        
        print("ğŸ¯ MELHOR CONFIGURAÃ‡ÃƒO:")
        print(f"ğŸ† Scaler: {melhor_scaler}")
        print(f"ğŸ¯ AcurÃ¡cia: {melhores_metricas['acuracia']:.1%}")
        print(f"ğŸ“Š RÂ²: {melhores_metricas['r2']:.4f}")
        
        # ComparaÃ§Ã£o com sem normalizaÃ§Ã£o
        if 'Sem NormalizaÃ§Ã£o' in resultados_normalizacao:
            sem_norm = resultados_normalizacao['Sem NormalizaÃ§Ã£o']
            melhor_norm = melhores_metricas
            
            melhora_acuracia = melhor_norm['acuracia'] - sem_norm['acuracia']
            melhora_r2 = melhor_norm['r2'] - sem_norm['r2']
            
            print(f"\nğŸ“ˆ MELHORA COMPARADA Ã€ SEM NORMALIZAÃ‡ÃƒO:")
            print(f"ğŸ¯ AcurÃ¡cia: {melhora_acuracia:+.1%}")
            print(f"ğŸ“Š RÂ²: {melhora_r2:+.4f}")
            
            if melhora_acuracia > 0.01:  # Melhora significativa
                print("âœ… NormalizaÃ§Ã£o trouxe melhora significativa!")
            elif melhora_acuracia > 0:
                print("âœ… NormalizaÃ§Ã£o trouxe leve melhora")
            else:
                print("âš ï¸ NormalizaÃ§Ã£o nÃ£o melhorou o desempenho")
        
        return resultados_normalizacao, melhor_scaler
    
    def executar_teste_completo(self):
        """
        Executa todo o pipeline de teste de normalizaÃ§Ã£o e anÃ¡lise de features
        """
        try:
            # 1-3: PreparaÃ§Ã£o dos dados
            self.carregar_dados()
            self.engenharia_features()
            self.criar_target()
            
            # 4: AnÃ¡lise exploratÃ³ria das features originais
            print("\n" + "="*60)
            print("ğŸ“Š TESTE 1: FEATURES ORIGINAIS")
            print("="*60)
            correlacoes_orig, corr_matrix_orig, dataset_orig = self.analisar_features()
            resultados_orig, melhor_scaler_orig = self.comparar_normalizacao()
            
            # 5-7: CriaÃ§Ã£o e anÃ¡lise de features avanÃ§adas
            print("\n" + "="*60)
            print("ğŸš€ TESTE 2: FEATURES AVANÃ‡ADAS")
            print("="*60)
            features_avancadas = self.criar_features_avancadas()
            melhores_features, correlacoes_melhoradas = self.selecionar_melhores_features()
            
            # 8: Teste com melhores features
            print("\n" + "="*60)
            print("ğŸ¯ TESTE 3: MELHORES FEATURES SELECIONADAS")
            print("="*60)
            resultados_melhoradas, melhor_scaler_melhorado = self.comparar_normalizacao(melhores_features)
            
            # 9: ValidaÃ§Ã£o cruzada com features originais
            print("\n" + "="*60)
            print("ğŸ”„ TESTE 4: VALIDAÃ‡ÃƒO CRUZADA - FEATURES ORIGINAIS")
            print("="*60)
            cv_orig, melhor_cv_orig = self.validacao_cruzada_acuracia()
            
            # 10: ValidaÃ§Ã£o cruzada com melhores features
            print("\n" + "="*60)
            print("ğŸ”„ TESTE 5: VALIDAÃ‡ÃƒO CRUZADA - MELHORES FEATURES")
            print("="*60)
            cv_melhoradas, melhor_cv_melhorado = self.validacao_cruzada_acuracia(melhores_features)
            
            # ComparaÃ§Ã£o final
            print("\n" + "="*60)
            print("ï¿½ COMPARAÃ‡ÃƒO FINAL DOS RESULTADOS")
            print("="*60)
            
            # Melhor resultado original
            melhor_orig = max(resultados_orig.values(), key=lambda x: x['acuracia'])
            melhor_melhorado = max(resultados_melhoradas.values(), key=lambda x: x['acuracia'])
            
            print("ğŸ† RESULTADOS COMPARATIVOS:")
            print(f"\n1ï¸âƒ£ Features Originais (melhor resultado):")
            print(f"   ï¿½ AcurÃ¡cia: {melhor_orig['acuracia']:.1%}")
            print(f"   ğŸ“Š RÂ²: {melhor_orig['r2']:.4f}")
            print(f"   ğŸ”§ Scaler: {melhor_scaler_orig}")
            
            print(f"\n2ï¸âƒ£ Features Melhoradas (melhor resultado):")
            print(f"   ğŸ¯ AcurÃ¡cia: {melhor_melhorado['acuracia']:.1%}")
            print(f"   ğŸ“Š RÂ²: {melhor_melhorado['r2']:.4f}")
            print(f"   ğŸ”§ Scaler: {melhor_scaler_melhorado}")
            
            # Calcular melhoria
            melhoria_acuracia = melhor_melhorado['acuracia'] - melhor_orig['acuracia']
            melhoria_r2 = melhor_melhorado['r2'] - melhor_orig['r2']
            
            print(f"\nğŸ“ˆ MELHORIA OBTIDA:")
            print(f"   ğŸ¯ AcurÃ¡cia: {melhoria_acuracia:+.1%}")
            print(f"   ğŸ“Š RÂ²: {melhoria_r2:+.4f}")
            
            if melhoria_acuracia > 0.02:
                print("   âœ… MELHORIA SIGNIFICATIVA!")
            elif melhoria_acuracia > 0:
                print("   âœ… Leve melhoria")
            else:
                print("   âš ï¸ Sem melhoria significativa")
            
            # Resumo final
            print("\n" + "="*50)
            print("ğŸ¯ RESUMO FINAL - COMPLETO")
            print("="*50)
            print(f"ğŸ“Š Dataset: {len(self.X)} observaÃ§Ãµes do IBOVESPA")
            
            # Resultados do teste holdout
            print(f"\nğŸ§ª TESTE HOLDOUT (70/30):")
            print(f"ğŸ† Melhor configuraÃ§Ã£o: {melhor_scaler_melhorado} + Features Otimizadas")
            print(f"ğŸ¯ AcurÃ¡cia final: {melhor_melhorado['acuracia']:.1%}")
            print(f"ğŸ“Š RÂ² final: {melhor_melhorado['r2']:.4f}")
            
            # Resultados da validaÃ§Ã£o cruzada
            melhor_cv_result = cv_melhoradas[melhor_cv_melhorado]
            print(f"\nğŸ”„ VALIDAÃ‡ÃƒO CRUZADA (5-Fold):")
            print(f"ğŸ† Melhor configuraÃ§Ã£o CV: {melhor_cv_melhorado} + Features Otimizadas")
            print(f"ğŸ¯ AcurÃ¡cia CV: {melhor_cv_result['acuracia_mean']:.1%} (Â±{melhor_cv_result['acuracia_std']:.1%})")
            print(f"ğŸ“Š RÂ² CV: {melhor_cv_result['r2_mean']:.4f} (Â±{melhor_cv_result['r2_std']:.4f})")
            
            # ComparaÃ§Ã£o entre mÃ©todos
            diff_acuracia = melhor_melhorado['acuracia'] - melhor_cv_result['acuracia_mean']
            print(f"\nğŸ“ˆ COMPARAÃ‡ÃƒO MÃ‰TODOS:")
            print(f"ğŸ”€ DiferenÃ§a Holdout vs CV: {diff_acuracia:+.1%}")
            
            if abs(diff_acuracia) < 0.02:
                print("âœ… Resultados consistentes entre mÃ©todos!")
            elif diff_acuracia > 0.02:
                print("âš ï¸ PossÃ­vel overfitting (holdout muito superior)")
            else:
                print("âš ï¸ Holdout pode ter sido pessimista")
                
            print(f"ğŸ“ˆ Qualidade: {'âœ… Excelente' if melhor_cv_result['acuracia_mean'] >= 0.6 else 'âœ… SatisfatÃ³ria' if melhor_cv_result['acuracia_mean'] >= 0.55 else 'âš ï¸ Pode melhorar'}")
            print("")
            print("âœ… AnÃ¡lise completa com validaÃ§Ã£o cruzada concluÃ­da!")
            
            return {
                'originais': resultados_orig,
                'melhoradas': resultados_melhoradas,
                'melhor_scaler_orig': melhor_scaler_orig,
                'melhor_scaler_melhorado': melhor_scaler_melhorado,
                'melhores_features': melhores_features,
                'melhoria_acuracia': melhoria_acuracia,
                'melhoria_r2': melhoria_r2,
                'cv_originais': cv_orig,
                'cv_melhoradas': cv_melhoradas,
                'melhor_cv_orig': melhor_cv_orig,
                'melhor_cv_melhorado': melhor_cv_melhorado
            }
            
        except Exception as e:
            print(f"âŒ Erro durante a execuÃ§Ã£o: {e}")
            return None

    def analisar_features(self):
        """
        5. ANÃLISE EXPLORATÃ“RIA DAS FEATURES
        Analisa correlaÃ§Ãµes, importÃ¢ncia e distribuiÃ§Ãµes
        """
        print("\n" + "="*60)
        print("ğŸ” ANÃLISE EXPLORATÃ“RIA DAS FEATURES")
        print("="*60)
        
        # Preparar dados para anÃ¡lise
        features = ['MM5', 'MM20', 'MM50', 'RSI', 'Volatilidade', 'Volume_Norm', 'Posicao_Canal']
        dataset = self.data[features + ['Target']].dropna()
        
        print(f"ğŸ“Š EstatÃ­sticas Descritivas:")
        print(dataset[features].describe())
        
        # CorrelaÃ§Ã£o com target
        print(f"\nğŸ“ˆ CorrelaÃ§Ã£o com Target (Retorno Futuro):")
        correlacoes = dataset[features].corrwith(dataset['Target']).sort_values(key=abs, ascending=False)
        for feat, corr in correlacoes.items():
            simbolo = "ğŸ”´" if abs(corr) > 0.1 else "ğŸŸ¡" if abs(corr) > 0.05 else "ğŸŸ¢"
            print(f"   {simbolo} {feat}: {corr:.4f}")
        
        # Matriz de correlaÃ§Ã£o entre features
        print(f"\nğŸ”„ CorrelaÃ§Ãµes entre Features:")
        corr_matrix = dataset[features].corr()
        
        # Identificar correlaÃ§Ãµes altas (multicolinearidade)
        high_corr_pairs = []
        for i in range(len(features)):
            for j in range(i+1, len(features)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.8:
                    high_corr_pairs.append((features[i], features[j], corr_val))
        
        if high_corr_pairs:
            print("   âš ï¸ CorrelaÃ§Ãµes altas detectadas (multicolinearidade):")
            for feat1, feat2, corr in high_corr_pairs:
                print(f"     {feat1} <-> {feat2}: {corr:.3f}")
        else:
            print("   âœ… Sem multicolinearidade significativa")
        
        # AnÃ¡lise de distribuiÃ§Ã£o do target
        print(f"\nğŸ“Š AnÃ¡lise do Target:")
        target_stats = dataset['Target'].describe()
        print(f"   MÃ©dia: {target_stats['mean']:.6f}")
        print(f"   Desvio: {target_stats['std']:.6f}")
        print(f"   Assimetria: {dataset['Target'].skew():.4f}")
        print(f"   Curtose: {dataset['Target'].kurtosis():.4f}")
        
        # Contar direÃ§Ãµes
        direcoes = (dataset['Target'] > 0).value_counts()
        print(f"   Altas: {direcoes[True]} ({direcoes[True]/len(dataset):.1%})")
        print(f"   Baixas: {direcoes[False]} ({direcoes[False]/len(dataset):.1%})")
        
        return correlacoes, corr_matrix, dataset
    
    def criar_features_avancadas(self):
        """
        6. ENGENHARIA DE FEATURES AVANÃ‡ADA
        Cria features mais sofisticadas baseadas na anÃ¡lise
        """
        print("\n" + "="*60)
        print("ğŸ§  CRIANDO FEATURES AVANÃ‡ADAS")
        print("="*60)
        
        # Features de momentum
        self.data['Momentum_3'] = self.data['Close'] / self.data['Close'].shift(3) - 1
        self.data['Momentum_7'] = self.data['Close'] / self.data['Close'].shift(7) - 1
        self.data['Momentum_14'] = self.data['Close'] / self.data['Close'].shift(14) - 1
        
        # Features de volatilidade
        self.data['Volatilidade_5'] = self.data['Retorno'].rolling(5).std()
        self.data['Volatilidade_10'] = self.data['Retorno'].rolling(10).std()
        self.data['Vol_Ratio'] = self.data['Volatilidade_5'] / self.data['Volatilidade_10']
        
        # Features de mÃ©dias mÃ³veis
        self.data['MM_Ratio_5_20'] = self.data['MM5'] / self.data['MM20']
        self.data['MM_Ratio_20_50'] = self.data['MM20'] / self.data['MM50']
        self.data['Distancia_MM20'] = (self.data['Close'] - self.data['MM20']) / self.data['MM20']
        
        # Features de volume
        self.data['Volume_MA5'] = self.data['Volume'].rolling(5).mean()
        self.data['Volume_Ratio_5'] = self.data['Volume'] / self.data['Volume_MA5']
        self.data['Volume_Trend'] = self.data['Volume_MA5'] / self.data['Volume_MA5'].shift(5) - 1
        
        # Features de canal/suporte/resistÃªncia
        self.data['Canal_Width'] = (self.data['Max_20'] - self.data['Min_20']) / self.data['Close']
        self.data['Distancia_Max'] = (self.data['Max_20'] - self.data['Close']) / self.data['Close']
        self.data['Distancia_Min'] = (self.data['Close'] - self.data['Min_20']) / self.data['Close']
        
        # Features de retorno acumulado
        self.data['Retorno_Acum_3'] = self.data['Retorno'].rolling(3).sum()
        self.data['Retorno_Acum_7'] = self.data['Retorno'].rolling(7).sum()
        
        # Features de RSI
        self.data['RSI_MA'] = self.data['RSI'].rolling(5).mean()
        self.data['RSI_Divergencia'] = self.data['RSI'] - self.data['RSI_MA']
        
        # Features de diferenciaÃ§Ã£o temporal
        self.data['RSI_Diff'] = self.data['RSI'].diff()
        self.data['Vol_Diff'] = self.data['Volatilidade'].diff()
        
        print("âœ… Features avanÃ§adas criadas:")
        features_avancadas = [
            'Momentum_3', 'Momentum_7', 'Momentum_14',
            'Volatilidade_5', 'Vol_Ratio', 
            'MM_Ratio_5_20', 'MM_Ratio_20_50', 'Distancia_MM20',
            'Volume_Ratio_5', 'Volume_Trend',
            'Canal_Width', 'Distancia_Max', 'Distancia_Min',
            'Retorno_Acum_3', 'Retorno_Acum_7',
            'RSI_MA', 'RSI_Divergencia', 'RSI_Diff', 'Vol_Diff'
        ]
        
        for i, feat in enumerate(features_avancadas, 1):
            print(f"   {i:2d}. {feat}")
        
        return features_avancadas
    
    def selecionar_melhores_features(self, max_features=10):
        """
        7. SELEÃ‡ÃƒO DE FEATURES BASEADA EM CORRELAÃ‡ÃƒO
        Seleciona as features com maior correlaÃ§Ã£o absoluta com o target
        """
        print("\n" + "="*60)
        print("ğŸ¯ SELEÃ‡ÃƒO DAS MELHORES FEATURES")
        print("="*60)
        
        # Todas as features disponÃ­veis
        todas_features = [
            'MM5', 'MM20', 'MM50', 'RSI', 'Volatilidade', 'Volume_Norm', 'Posicao_Canal',
            'Momentum_3', 'Momentum_7', 'Momentum_14',
            'Volatilidade_5', 'Vol_Ratio', 
            'MM_Ratio_5_20', 'MM_Ratio_20_50', 'Distancia_MM20',
            'Volume_Ratio_5', 'Volume_Trend',
            'Canal_Width', 'Distancia_Max', 'Distancia_Min',
            'Retorno_Acum_3', 'Retorno_Acum_7',
            'RSI_MA', 'RSI_Divergencia', 'RSI_Diff', 'Vol_Diff'
        ]
        
        # Preparar dataset
        dataset = self.data[todas_features + ['Target']].dropna()
        
        # Calcular correlaÃ§Ãµes absolutas
        correlacoes = dataset[todas_features].corrwith(dataset['Target']).abs().sort_values(ascending=False)
        
        # Selecionar top features
        melhores_features = correlacoes.head(max_features).index.tolist()
        
        print(f"ğŸ† Top {max_features} Features (por correlaÃ§Ã£o absoluta):")
        for i, (feat, corr) in enumerate(correlacoes.head(max_features).items(), 1):
            simbolo = "ğŸ”´" if corr > 0.1 else "ğŸŸ¡" if corr > 0.05 else "ğŸŸ¢"
            print(f"   {i:2d}. {simbolo} {feat}: {corr:.4f}")
        
        # Verificar melhoria
        print(f"\nğŸ“ˆ ComparaÃ§Ã£o com features originais:")
        features_originais = ['MM5', 'MM20', 'MM50', 'RSI', 'Volatilidade', 'Volume_Norm', 'Posicao_Canal']
        corr_originais = dataset[features_originais].corrwith(dataset['Target']).abs().mean()
        corr_melhores = correlacoes.head(max_features).mean()
        
        print(f"   Features originais: {corr_originais:.4f} (correlaÃ§Ã£o mÃ©dia)")
        print(f"   Melhores features: {corr_melhores:.4f} (correlaÃ§Ã£o mÃ©dia)")
        print(f"   Melhoria: {((corr_melhores/corr_originais - 1) * 100):+.1f}%")
        
        return melhores_features, correlacoes
    
    def validacao_cruzada_acuracia(self, features=None, cv_folds=5):
        """
        Realiza validaÃ§Ã£o cruzada para medir acurÃ¡cia de direÃ§Ã£o
        """
        print("\n" + "="*70)
        print("ğŸ”„ VALIDAÃ‡ÃƒO CRUZADA - ACURÃCIA DE DIREÃ‡ÃƒO")
        print(f"ğŸ¯ K-Fold: {cv_folds} folds")
        print("="*70)
        
        # Preparar dados
        X, y = self.preparar_dataset(features)
        
        # Diferentes tipos de scalers
        scalers = {
            'Sem NormalizaÃ§Ã£o': None,
            'StandardScaler': StandardScaler(),
            'MinMaxScaler': MinMaxScaler(),
            'RobustScaler': RobustScaler(),
            'Normalizer': Normalizer()
        }
        
        resultados_cv = {}
        
        # FunÃ§Ã£o personalizada para calcular acurÃ¡cia de direÃ§Ã£o
        def acuracia_direcao(y_true, y_pred):
            y_true_dir = (y_true > 0).astype(int)
            y_pred_dir = (y_pred > 0).astype(int)
            return np.mean(y_true_dir == y_pred_dir)
        
        from sklearn.model_selection import cross_val_score
        from sklearn.metrics import make_scorer
        
        # Criar scorer personalizado
        scorer_acuracia = make_scorer(acuracia_direcao)
        
        for nome_scaler, scaler in scalers.items():
            print(f"\nğŸ§ª ValidaÃ§Ã£o cruzada: {nome_scaler}")
            print("-" * 50)
            
            try:
                # Criar pipeline
                if scaler is None:
                    modelo = LinearRegression()
                else:
                    modelo = Pipeline([
                        ('scaler', scaler),
                        ('regressor', LinearRegression())
                    ])
                
                # ValidaÃ§Ã£o cruzada para acurÃ¡cia de direÃ§Ã£o
                scores_acuracia = cross_val_score(
                    modelo, X, y, 
                    cv=cv_folds, 
                    scoring=scorer_acuracia,
                    n_jobs=-1
                )
                
                # ValidaÃ§Ã£o cruzada para RÂ²
                scores_r2 = cross_val_score(
                    modelo, X, y, 
                    cv=cv_folds, 
                    scoring='r2',
                    n_jobs=-1
                )
                
                # Armazenar resultados
                resultados_cv[nome_scaler] = {
                    'acuracia_scores': scores_acuracia,
                    'acuracia_mean': scores_acuracia.mean(),
                    'acuracia_std': scores_acuracia.std(),
                    'r2_scores': scores_r2,
                    'r2_mean': scores_r2.mean(),
                    'r2_std': scores_r2.std()
                }
                
                # Exibir resultados
                print(f"ğŸ“Š AcurÃ¡cia CV: {scores_acuracia.mean():.1%} (Â±{scores_acuracia.std():.1%})")
                print(f"ğŸ“Š RÂ² CV: {scores_r2.mean():.4f} (Â±{scores_r2.std():.4f})")
                print(f"ğŸ“Š Folds individuais acurÃ¡cia: {[f'{s:.1%}' for s in scores_acuracia]}")
                
                qualidade = "âœ… Excelente" if scores_acuracia.mean() >= 0.6 else "âœ… SatisfatÃ³ria" if scores_acuracia.mean() >= 0.55 else "âš ï¸ Pode melhorar"
                print(f"ğŸ“ˆ Qualidade: {qualidade}")
                
            except Exception as e:
                print(f"âŒ Erro com {nome_scaler}: {e}")
                continue
        
        # Ranking por acurÃ¡cia CV
        print("\n" + "="*70)
        print("ğŸ† RANKING VALIDAÃ‡ÃƒO CRUZADA - ACURÃCIA")
        print("="*70)
        
        ranking_cv = sorted(resultados_cv.items(), 
                           key=lambda x: x[1]['acuracia_mean'], reverse=True)
        
        for i, (nome, metricas) in enumerate(ranking_cv, 1):
            print(f"{i}Âº ğŸ¥‡ {nome}:")
            print(f"   ğŸ¯ AcurÃ¡cia CV: {metricas['acuracia_mean']:.1%} (Â±{metricas['acuracia_std']:.1%})")
            print(f"   ğŸ“Š RÂ² CV: {metricas['r2_mean']:.4f} (Â±{metricas['r2_std']:.4f})")
            print()
        
        # Resumo da melhor configuraÃ§Ã£o
        melhor_nome_cv = ranking_cv[0][0]
        melhor_cv = ranking_cv[0][1]
        
        print("ğŸ¯ MELHOR CONFIGURAÃ‡ÃƒO (VALIDAÃ‡ÃƒO CRUZADA):")
        print(f"ğŸ† Scaler: {melhor_nome_cv}")
        print(f"ğŸ¯ AcurÃ¡cia CV: {melhor_cv['acuracia_mean']:.1%} (Â±{melhor_cv['acuracia_std']:.1%})")
        print(f"ğŸ“Š RÂ² CV: {melhor_cv['r2_mean']:.4f} (Â±{melhor_cv['r2_std']:.4f})")
        
        # Intervalo de confianÃ§a aproximado (95%)
        ic_inf = melhor_cv['acuracia_mean'] - 1.96 * melhor_cv['acuracia_std']
        ic_sup = melhor_cv['acuracia_mean'] + 1.96 * melhor_cv['acuracia_std']
        print(f"ğŸ“Š Intervalo 95%: [{ic_inf:.1%}, {ic_sup:.1%}]")
        
        return resultados_cv, melhor_nome_cv


def main():
    """
    FunÃ§Ã£o principal para executar o projeto
    Seguindo orientaÃ§Ãµes do professor: 10 anos de dados + divisÃ£o 70/30
    """
    print("ğŸ“š MACHINE LEARNING - LINEAR REGRESSION NO IBOVESPA")
    print("ğŸ”¬ ANÃLISE DE FEATURES + TESTE DE NORMALIZAÃ‡ÃƒO")
    print("ğŸ¯ ConfiguraÃ§Ã£o Professor: 10 anos + DivisÃ£o 70/30")
    print("ğŸ’¡ Dados do Plano Real para maior robustez histÃ³rica")
    print("=" * 70)
    
    # Criar modelo
    ml = MLIbovespaNormalizacao()
    
    # Executar anÃ¡lise completa
    resultados = ml.executar_teste_completo()
    
    if resultados:
        print(f"\nğŸ‰ AnÃ¡lise completa concluÃ­da!")
        
        # Extrair melhores resultados
        melhor_orig = max(resultados['originais'].values(), key=lambda x: x['acuracia'])
        melhor_melhorado = max(resultados['melhoradas'].values(), key=lambda x: x['acuracia'])
        
        print(f"\nğŸ“Š RESUMO EXECUTIVO:")
        print(f"ğŸ”§ Melhor scaler original: {resultados['melhor_scaler_orig']}")
        print(f"ğŸ”§ Melhor scaler otimizado: {resultados['melhor_scaler_melhorado']}")
        print(f"ğŸ“ˆ Melhoria na acurÃ¡cia: {resultados['melhoria_acuracia']:+.1%}")
        print(f"ï¿½ Melhoria no RÂ²: {resultados['melhoria_r2']:+.4f}")
        print(f"ğŸ¯ AcurÃ¡cia final: {melhor_melhorado['acuracia']:.1%}")
    else:
        print("\nâŒ AnÃ¡lise nÃ£o foi concluÃ­da devido a erros.")
    
    return ml, resultados


if __name__ == "__main__":
    modelo, resultados = main()
