"""
Machine Learning Aplicado ao IBOVESPA - Versﾃ｣o Didﾃ｡tica Simples
Com Validaﾃｧﾃ｣o Cruzada para demonstrar os conceitos fundamentais do curso
"""

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Imports do Scikit-Learn
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def main():
    print("答 MACHINE LEARNING - LINEAR REGRESSION NO IBOVESPA")
    print("溌 VERSﾃグ DIDﾃゝICA COM VALIDAﾃﾃグ CRUZADA")
    print("識 Mﾃｩtricas: Rﾂｲ, RMSE, MAE + ACURﾃ，IA DE DIREﾃﾃグ")
    print("=" * 60)
    
    # 1. CARREGAMENTO DE DADOS
    print("1. CARREGANDO DADOS DO IBOVESPA...")
    end_date = datetime.now()
    start_date = end_date - timedelta(days=10*365)  # 10 anos
    
    ibov = yf.download('^BVSP', start=start_date, end=end_date)
    print(f"笨 {len(ibov)} dias de dados carregados")
    
    # 2. CRIAﾃﾃグ DE FEATURES BﾃヾICAS
    print("\n2. CRIANDO FEATURES...")
    data = pd.DataFrame()
    data['Close'] = ibov['Close']
    data['Volume'] = ibov['Volume']
    data['High'] = ibov['High']
    data['Low'] = ibov['Low']
    
    # Features tﾃｩcnicas bﾃ｡sicas
    data['MM5'] = data['Close'].rolling(5).mean()
    data['MM20'] = data['Close'].rolling(20).mean()
    data['Volatilidade'] = data['Close'].pct_change().rolling(20).std()
    data['RSI'] = calculate_rsi(data['Close'])
    data['Volume_Norm'] = data['Volume'] / data['Volume'].rolling(20).mean()
    
    # 3. CRIAﾃﾃグ DO TARGET
    print("3. CRIANDO TARGET...")
    data['Retorno_Futuro'] = data['Close'].pct_change().shift(-1)
    data['Direcao_Futura'] = (data['Retorno_Futuro'] > 0).astype(int)
    
    # 4. PREPARAﾃﾃグ DOS DADOS
    print("4. PREPARANDO DADOS...")
    features = ['MM5', 'MM20', 'Volatilidade', 'RSI', 'Volume_Norm']
    data_clean = data[features + ['Retorno_Futuro', 'Direcao_Futura']].dropna()
    
    X = data_clean[features]
    y_reg = data_clean['Retorno_Futuro']  # Para regressﾃ｣o
    y_class = data_clean['Direcao_Futura']  # Para acurﾃ｡cia de direﾃｧﾃ｣o
    
    print(f"笨 {len(X)} observaﾃｧﾃｵes preparadas")
    print(f"笨 {len(features)} features utilizadas")
    
    # 5. DIVISﾃグ TREINO/TESTE (70/30)
    print("\n5. DIVIDINDO DADOS (70% TREINO / 30% TESTE)...")
    X_train, X_test, y_reg_train, y_reg_test, y_class_train, y_class_test = train_test_split(
        X, y_reg, y_class, test_size=0.3, random_state=42, shuffle=False
    )
    
    print(f"投 Treino: {len(X_train)} observaﾃｧﾃｵes")
    print(f"投 Teste: {len(X_test)} observaﾃｧﾃｵes")
    
    # 6. TREINAMENTO DO MODELO
    print("\n6. TREINAMENTO - LINEAR REGRESSION...")
    
    # Normalizaﾃｧﾃ｣o
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Modelo
    model = LinearRegression()
    model.fit(X_train_scaled, y_reg_train)
    
    # 7. AVALIAﾃﾃグ NO TESTE
    print("\n7. AVALIAﾃﾃグ NO CONJUNTO DE TESTE...")
    y_pred = model.predict(X_test_scaled)
    
    # Mﾃｩtricas de regressﾃ｣o
    r2 = r2_score(y_reg_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_reg_test, y_pred))
    mae = mean_absolute_error(y_reg_test, y_pred)
    
    # Acurﾃ｡cia de direﾃｧﾃ｣o
    direcao_pred = (y_pred > 0).astype(int)
    acuracia = np.mean(direcao_pred == y_class_test)
    
    print(f"投 Rﾂｲ: {r2:.4f}")
    print(f"投 RMSE: {rmse:.4f}")
    print(f"投 MAE: {mae:.4f}")
    print(f"識 Acurﾃ｡cia de Direﾃｧﾃ｣o: {acuracia:.1%}")
    
    # 8. VALIDAﾃﾃグ CRUZADA
    print("\n8. VALIDAﾃﾃグ CRUZADA (5-FOLD)...")
    
    # Para Rﾂｲ
    cv_scores_r2 = cross_val_score(model, X_train_scaled, y_reg_train, cv=5, scoring='r2')
    print(f"投 Rﾂｲ CV: {cv_scores_r2.mean():.4f} (ﾂｱ{cv_scores_r2.std():.4f})")
    
    # Para acurﾃ｡cia de direﾃｧﾃ｣o (manual)
    from sklearn.model_selection import KFold
    kfold = KFold(n_splits=5, shuffle=False)
    cv_accuracies = []
    
    for train_idx, val_idx in kfold.split(X_train_scaled):
        X_cv_train, X_cv_val = X_train_scaled[train_idx], X_train_scaled[val_idx]
        y_cv_train, y_cv_val = y_reg_train.iloc[train_idx], y_reg_train.iloc[val_idx]
        y_class_cv_val = y_class_train.iloc[val_idx]
        
        model_cv = LinearRegression()
        model_cv.fit(X_cv_train, y_cv_train)
        y_cv_pred = model_cv.predict(X_cv_val)
        
        direcao_cv_pred = (y_cv_pred > 0).astype(int)
        acc_cv = np.mean(direcao_cv_pred == y_class_cv_val)
        cv_accuracies.append(acc_cv)
    
    cv_acc_mean = np.mean(cv_accuracies)
    cv_acc_std = np.std(cv_accuracies)
    
    print(f"識 Acurﾃ｡cia CV: {cv_acc_mean:.1%} (ﾂｱ{cv_acc_std:.1%})")
    
    # 9. RESUMO FINAL
    print("\n" + "="*50)
    print("識 RESUMO FINAL")
    print("="*50)
    print(f"投 Dataset: {len(data_clean)} observaﾃｧﾃｵes")
    print(f"投 Features: {len(features)}")
    print(f"投 Perﾃｭodo: 10 anos")
    print(f"投 Divisﾃ｣o: 70% treino / 30% teste")
    print("\nｧｪ RESULTADOS HOLDOUT:")
    print(f"投 Rﾂｲ: {r2:.4f}")
    print(f"識 Acurﾃ｡cia: {acuracia:.1%}")
    print("\n売 RESULTADOS VALIDAﾃﾃグ CRUZADA:")
    print(f"投 Rﾂｲ CV: {cv_scores_r2.mean():.4f} (ﾂｱ{cv_scores_r2.std():.4f})")
    print(f"識 Acurﾃ｡cia CV: {cv_acc_mean:.1%} (ﾂｱ{cv_acc_std:.1%})")
    print("\n笨 Anﾃ｡lise concluﾃｭda!")

def calculate_rsi(prices, window=14):
    """Calcula o RSI (Relative Strength Index)"""
    delta = prices.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

if __name__ == "__main__":
    main()
